{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from random import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = 'ml_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "chpn-p10_format0.mid\n",
      "chpn-p11_format0.mid\n",
      "chpn-p12_format0.mid\n",
      "chpn-p13_format0.mid\n",
      "chpn-p14_format0.mid\n",
      "chpn-p15_format0.mid\n",
      "chpn-p16_format0.mid\n",
      "chpn-p17_format0.mid\n",
      "chpn-p18_format0.mid\n",
      "chpn-p19_format0.mid\n",
      "chpn-p1_format0.mid\n",
      "chpn-p20_format0.mid\n",
      "chpn-p21_format0.mid\n",
      "chpn-p22_format0.mid\n",
      "chpn-p23_format0.mid\n",
      "chpn-p24_format0.mid\n",
      "chpn-p2_format0.mid\n",
      "chpn-p3_format0.mid\n",
      "chpn-p4_format0.mid\n",
      "chpn-p5_format0.mid\n",
      "chpn-p6_format0.mid\n",
      "chpn-p7_format0.mid\n",
      "chpn-p8_format0.mid\n",
      "chpn-p9_format0.mid\n",
      "scale.mid\n"
     ]
    }
   ],
   "source": [
    "midi_files = set()\n",
    "for csv_file in listdir(data_dir):\n",
    "    midi_file = '.'.join(csv_file.split('.')[:2])\n",
    "    midi_files.add(midi_file)\n",
    "print(len(midi_files))\n",
    "for midi_file in sorted(midi_files):\n",
    "    print(midi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['chpn-p6_format0.mid', 'chpn-p24_format0.mid', 'chpn-p1_format0.mid', 'chpn-p23_format0.mid', 'chpn-p17_format0.mid', 'chpn-p13_format0.mid', 'chpn-p18_format0.mid', 'chpn-p19_format0.mid', 'chpn-p21_format0.mid', 'scale.mid', 'chpn-p15_format0.mid', 'chpn-p2_format0.mid', 'chpn-p3_format0.mid', 'chpn-p7_format0.mid', 'chpn-p11_format0.mid', 'chpn-p16_format0.mid', 'chpn-p22_format0.mid', 'chpn-p20_format0.mid', 'chpn-p10_format0.mid', 'chpn-p9_format0.mid', 'chpn-p4_format0.mid', 'chpn-p8_format0.mid'])\n",
      "set(['chpn-p14_format0.mid', 'chpn-p5_format0.mid', 'chpn-p12_format0.mid'])\n",
      "22\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# midi_files_list = list(midi_files)\n",
    "# offset = int(len(midi_files_list)*0.8)\n",
    "# shuffle(midi_files_list)\n",
    "# train_set = set(midi_files_list[:offset])\n",
    "# test_set = set(midi_files_list[offset:])\n",
    "test_set = {'chpn-p12_format0.mid', 'chpn-p14_format0.mid', 'chpn-p5_format0.mid'}\n",
    "train_set = midi_files - test_set\n",
    "print(train_set)\n",
    "print(test_set)\n",
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(data_dir, train_set, test_set, note_from=0, note_to=127, take_every_nth_negative_sample=1, sep=';'):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for csv_file in listdir(data_dir):\n",
    "        csv_file_split = csv_file.split('.')\n",
    "        midi_file = '.'.join(csv_file_split[:2])\n",
    "        note = int(csv_file_split[2])\n",
    "        if note >= note_from and note <= note_to:\n",
    "            if midi_file in train_set:\n",
    "                read_file(join(data_dir, csv_file), X_train, y_train, take_every_nth_negative_sample, sep)\n",
    "            elif midi_file in test_set:\n",
    "                read_file(join(data_dir, csv_file), X_test, y_test, 1, sep)\n",
    "    return np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "\n",
    "\n",
    "def read_file(path_to_file, X, y, take_every_nth_negative_sample, sep):\n",
    "    with open(path_to_file) as f:\n",
    "        y_value_0_count = 0\n",
    "        for line in f:\n",
    "            line_split = line.rstrip().split(sep)\n",
    "            line_length = len(line_split)\n",
    "            \n",
    "            X_value = [float(number) for number in line_split[:line_length-1]]\n",
    "            y_value = int(line_split[line_length-1])\n",
    "            if y_value == 1:\n",
    "                X.append(X_value)\n",
    "                y.append(y_value)\n",
    "            else:\n",
    "                if y_value_0_count % take_every_nth_negative_sample == 0:\n",
    "                    X.append(X_value)\n",
    "                    y.append(y_value)\n",
    "                y_value_0_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read start: 2016-12-18 16:08:55.649000\n",
      "read end: 2016-12-18 16:18:35.413000\n"
     ]
    }
   ],
   "source": [
    "print('read start: ' + str(datetime.datetime.now()))\n",
    "# X_train, y_train, X_test, y_test = read_data(\n",
    "#     data_dir, train_set, test_set, note_from=51, note_to=72, take_every_nth_negative_sample=250\n",
    "# )\n",
    "# X_train, y_train, X_test, y_test = read_data(\n",
    "#     data_dir, train_set, test_set, note_from=24, note_to=50, take_every_nth_negative_sample=750\n",
    "# )\n",
    "X_train, y_train, X_test, y_test = read_data(data_dir, train_set, test_set, take_every_nth_negative_sample=1)\n",
    "print('read end: ' + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51379380L, 10L)\n",
      "(3180918L, 10L)\n",
      "10952\n",
      "824\n",
      "0.000213159442562\n",
      "0.000259044716022\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(sum(y_train))\n",
    "print(sum(y_test))\n",
    "print(float(sum(y_train))/X_train.shape[0])\n",
    "print(float(sum(y_test))/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit start: 2016-12-18 16:20:11.970000\n",
      "fit end: 2016-12-18 17:07:33.381000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00  51368428\n",
      "          1       1.00      0.85      0.92     10952\n",
      "\n",
      "avg / total       1.00      1.00      1.00  51379380\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00   3180094\n",
      "          1       0.81      0.50      0.62       824\n",
      "\n",
      "avg / total       1.00      1.00      1.00   3180918\n",
      "\n",
      "predict end: 2016-12-18 17:08:27.155000\n"
     ]
    }
   ],
   "source": [
    "print('fit start: ' + str(datetime.datetime.now()))\n",
    "estimator = make_pipeline(StandardScaler(), RandomForestClassifier(n_jobs=6))\n",
    "estimator.fit(X_train, y_train)\n",
    "print('fit end: ' + str(datetime.datetime.now()))\n",
    "print(classification_report(y_train, estimator.predict(X_train)))\n",
    "print(classification_report(y_test, estimator.predict(X_test)))\n",
    "print('predict end: ' + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('random_forest_22_midis.cpickle', 'wb') as f:\n",
    "    cPickle.dump(estimator, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00   3180094\n",
      "          1       0.81      0.50      0.62       824\n",
      "\n",
      "avg / total       1.00      1.00      1.00   3180918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('random_forest_22_midis.cpickle', 'rb') as f:\n",
    "    loaded_estimator = cPickle.load(f)\n",
    "print(classification_report(y_test, loaded_estimator.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
