{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from random import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = 'ml_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "chpn-p10_format0.mid\n",
      "chpn-p11_format0.mid\n",
      "chpn-p12_format0.mid\n",
      "chpn-p13_format0.mid\n",
      "chpn-p14_format0.mid\n",
      "chpn-p15_format0.mid\n",
      "chpn-p16_format0.mid\n",
      "chpn-p17_format0.mid\n",
      "chpn-p18_format0.mid\n",
      "chpn-p19_format0.mid\n",
      "chpn-p1_format0.mid\n",
      "chpn-p20_format0.mid\n",
      "chpn-p21_format0.mid\n",
      "chpn-p22_format0.mid\n",
      "chpn-p23_format0.mid\n",
      "chpn-p24_format0.mid\n",
      "chpn-p2_format0.mid\n",
      "chpn-p3_format0.mid\n",
      "chpn-p4_format0.mid\n",
      "chpn-p5_format0.mid\n",
      "chpn-p6_format0.mid\n",
      "chpn-p7_format0.mid\n",
      "chpn-p8_format0.mid\n",
      "chpn-p9_format0.mid\n",
      "scale.mid\n"
     ]
    }
   ],
   "source": [
    "midi_files = set()\n",
    "for csv_file in listdir(data_dir):\n",
    "    midi_file = '.'.join(csv_file.split('.')[:2])\n",
    "    midi_files.add(midi_file)\n",
    "print(len(midi_files))\n",
    "for midi_file in sorted(midi_files):\n",
    "    print(midi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['chpn-p6_format0.mid', 'chpn-p24_format0.mid', 'chpn-p1_format0.mid', 'chpn-p23_format0.mid', 'chpn-p17_format0.mid', 'chpn-p13_format0.mid', 'chpn-p18_format0.mid', 'chpn-p19_format0.mid', 'chpn-p21_format0.mid', 'chpn-p15_format0.mid', 'chpn-p2_format0.mid', 'chpn-p5_format0.mid', 'chpn-p12_format0.mid', 'chpn-p3_format0.mid', 'chpn-p7_format0.mid', 'chpn-p11_format0.mid', 'chpn-p16_format0.mid', 'chpn-p22_format0.mid', 'chpn-p14_format0.mid', 'chpn-p20_format0.mid', 'chpn-p10_format0.mid', 'chpn-p9_format0.mid', 'chpn-p4_format0.mid', 'chpn-p8_format0.mid'])\n",
      "set(['scale.mid'])\n",
      "24\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# midi_files_list = list(midi_files)\n",
    "# offset = int(len(midi_files_list)*0.8)\n",
    "# shuffle(midi_files_list)\n",
    "# train_set = set(midi_files_list[:offset])\n",
    "# test_set = set(midi_files_list[offset:])\n",
    "test_set = {'scale.mid'}\n",
    "train_set = midi_files - test_set\n",
    "print(train_set)\n",
    "print(test_set)\n",
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(data_dir, train_set, test_set, note_from=0, note_to=127, take_every_nth_negative_sample=1, sep=';'):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for csv_file in listdir(data_dir):\n",
    "        csv_file_split = csv_file.split('.')\n",
    "        midi_file = '.'.join(csv_file_split[:2])\n",
    "        note = int(csv_file_split[2])\n",
    "        if note >= note_from and note <= note_to:\n",
    "            if midi_file in train_set:\n",
    "                read_file(join(data_dir, csv_file), X_train, y_train, take_every_nth_negative_sample, sep)\n",
    "            elif midi_file in test_set:\n",
    "                read_file(join(data_dir, csv_file), X_test, y_test, 1, sep)\n",
    "    return np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "\n",
    "\n",
    "def read_file(path_to_file, X, y, take_every_nth_negative_sample, sep):\n",
    "    with open(path_to_file) as f:\n",
    "        y_value_0_count = 0\n",
    "        for line in f:\n",
    "            line_split = line.rstrip().split(sep)\n",
    "            line_length = len(line_split)\n",
    "            \n",
    "            X_value = [float(number) for number in line_split[:line_length-1]]\n",
    "            y_value = int(line_split[line_length-1])\n",
    "            if y_value == 1:\n",
    "                X.append(X_value)\n",
    "                y.append(y_value)\n",
    "            else:\n",
    "                if y_value_0_count % take_every_nth_negative_sample == 0:\n",
    "                    X.append(X_value)\n",
    "                    y.append(y_value)\n",
    "                y_value_0_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read start: 2016-12-13 17:30:54.920000\n",
      "read end: 2016-12-13 17:37:27.754000\n"
     ]
    }
   ],
   "source": [
    "print('read start: ' + str(datetime.datetime.now()))\n",
    "# X_train, y_train, X_test, y_test = read_data(\n",
    "#     data_dir, train_set, test_set, note_from=51, note_to=72, take_every_nth_negative_sample=250\n",
    "# )\n",
    "# X_train, y_train, X_test, y_test = read_data(\n",
    "#     data_dir, train_set, test_set, note_from=24, note_to=50, take_every_nth_negative_sample=750\n",
    "# )\n",
    "X_train, y_train, X_test, y_test = read_data(data_dir, train_set, test_set, take_every_nth_negative_sample=1000)\n",
    "print('read end: ' + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66090L, 10L)\n",
      "(1067586L, 10L)\n",
      "11576\n",
      "200\n",
      "0.175155091542\n",
      "0.000187338537598\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(sum(y_train))\n",
    "print(sum(y_test))\n",
    "print(float(sum(y_train))/X_train.shape[0])\n",
    "print(float(sum(y_test))/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit start: 2016-12-13 17:37:27.947000\n",
      "fit end: 2016-12-13 17:37:41.226000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98     54514\n",
      "          1       0.96      0.85      0.90     11576\n",
      "\n",
      "avg / total       0.97      0.97      0.97     66090\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00   1067386\n",
      "          1       0.03      0.87      0.06       200\n",
      "\n",
      "avg / total       1.00      0.99      1.00   1067586\n",
      "\n",
      "predict end: 2016-12-13 17:37:42.416000\n"
     ]
    }
   ],
   "source": [
    "print('fit start: ' + str(datetime.datetime.now()))\n",
    "estimator = make_pipeline(StandardScaler(), MLPClassifier())\n",
    "estimator.fit(X_train, y_train)\n",
    "print('fit end: ' + str(datetime.datetime.now()))\n",
    "print(classification_report(y_train, estimator.predict(X_train)))\n",
    "print(classification_report(y_test, estimator.predict(X_test)))\n",
    "print('predict end: ' + str(datetime.datetime.now()))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
